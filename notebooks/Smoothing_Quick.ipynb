{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Smoothing_Quick: MediaPipe Built-in Smoothing Only\n",
        "\n",
        "This simple notebook extracts MediaPipe keypoints from a video using MediaPipe's built-in smoothing (enabled when `static_image_mode=False`). It saves time series CSV files for body, hands, and face.\n",
        "\n",
        "- Recommended for most use cases where smoothed keypoint positions are sufficient\n",
        "- For smoothing derivatives (speed, acceleration, jerk), use the full `Smoothing.ipynb` pipeline\n",
        "- Looking for the full signal-processing suite? See `Smoothing.ipynb` (Butterworth, Savitzkyâ€“Golay, Gaussian, and evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and Paths\n",
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "# Configure folders (relative to this notebook)\n",
        "input_folder = \"../data/interim\"  # place your .mp4 videos here\n",
        "output_folder = \"../results/Output_TimeSeries\"\n",
        "\n",
        "# Option: use existing CSVs from MediaPipe_keypoints_extraction\n",
        "use_existing_csvs = False\n",
        "input_csv_folder = \"../Mediapipe_results\"  # where *_body.csv, *_hands.csv, *_face.csv are located\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# List videos\n",
        "video_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\".mp4\", \".mov\", \".mkv\"))]\n",
        "print(\"Videos:\", video_files)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Landmark column headers\n",
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "markers_body = [\n",
        "    'NOSE','LEFT_EYE_INNER','LEFT_EYE','LEFT_EYE_OUTER','RIGHT_EYE_INNER','RIGHT_EYE','RIGHT_EYE_OUTER',\n",
        "    'LEFT_EAR','RIGHT_EAR','MOUTH_LEFT','MOUTH_RIGHT','LEFT_SHOULDER','RIGHT_SHOULDER','LEFT_ELBOW',\n",
        "    'RIGHT_ELBOW','LEFT_WRIST','RIGHT_WRIST','LEFT_PINKY','RIGHT_PINKY','LEFT_INDEX','RIGHT_INDEX',\n",
        "    'LEFT_THUMB','RIGHT_THUMB','LEFT_HIP','RIGHT_HIP','LEFT_KNEE','RIGHT_KNEE','LEFT_ANKLE','RIGHT_ANKLE',\n",
        "    'LEFT_HEEL','RIGHT_HEEL','LEFT_FOOT_INDEX','RIGHT_FOOT_INDEX']\n",
        "\n",
        "markers_hands = [\n",
        "    'LEFT_WRIST','LEFT_THUMB_CMC','LEFT_THUMB_MCP','LEFT_THUMB_IP','LEFT_THUMB_TIP','LEFT_INDEX_FINGER_MCP',\n",
        "    'LEFT_INDEX_FINGER_PIP','LEFT_INDEX_FINGER_DIP','LEFT_INDEX_FINGER_TIP','LEFT_MIDDLE_FINGER_MCP',\n",
        "    'LEFT_MIDDLE_FINGER_PIP','LEFT_MIDDLE_FINGER_DIP','LEFT_MIDDLE_FINGER_TIP','LEFT_RING_FINGER_MCP',\n",
        "    'LEFT_RING_FINGER_PIP','LEFT_RING_FINGER_DIP','LEFT_RING_FINGER_TIP','LEFT_PINKY_FINGER_MCP',\n",
        "    'LEFT_PINKY_FINGER_PIP','LEFT_PINKY_FINGER_DIP','LEFT_PINKY_FINGER_TIP',\n",
        "    'RIGHT_WRIST','RIGHT_THUMB_CMC','RIGHT_THUMB_MCP','RIGHT_THUMB_IP','RIGHT_THUMB_TIP','RIGHT_INDEX_FINGER_MCP',\n",
        "    'RIGHT_INDEX_FINGER_PIP','RIGHT_INDEX_FINGER_DIP','RIGHT_INDEX_FINGER_TIP','RIGHT_MIDDLE_FINGER_MCP',\n",
        "    'RIGHT_MIDDLE_FINGER_PIP','RIGHT_MIDDLE_FINGER_DIP','RIGHT_MIDDLE_FINGER_TIP','RIGHT_RING_FINGER_MCP',\n",
        "    'RIGHT_RING_FINGER_PIP','RIGHT_RING_FINGER_DIP','RIGHT_RING_FINGER_TIP','RIGHT_PINKY_FINGER_MCP',\n",
        "    'RIGHT_PINKY_FINGER_PIP','RIGHT_PINKY_FINGER_DIP','RIGHT_PINKY_FINGER_TIP']\n",
        "\n",
        "markers_face = [str(x) for x in range(478)]\n",
        "\n",
        "columns_body = ['time'] + [f\"{pos}_{m}\" for m in markers_body for pos in ['X','Y','Z','visibility']]\n",
        "columns_hands = ['time'] + [f\"{pos}_{m}\" for m in markers_hands for pos in ['X','Y','Z']]\n",
        "columns_face = ['time'] + [f\"{pos}_{m}\" for m in markers_face for pos in ['X','Y','Z']]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process videos with MediaPipe built-in smoothing or reuse existing CSVs\n",
        "for video_file in video_files:\n",
        "    base = os.path.splitext(video_file)[0]\n",
        "    video_path = os.path.join(input_folder, video_file)\n",
        "\n",
        "    if use_existing_csvs:\n",
        "        # Copy existing CSVs if present\n",
        "        for suffix in [\"_body.csv\", \"_hands.csv\", \"_face.csv\"]:\n",
        "            src = os.path.join(input_csv_folder, base + suffix)\n",
        "            dst = os.path.join(output_folder, base + suffix)\n",
        "            if os.path.exists(src):\n",
        "                shutil.copy2(src, dst)\n",
        "                print(f\"Copied existing: {os.path.basename(src)}\")\n",
        "            else:\n",
        "                print(f\"Missing expected file: {os.path.basename(src)}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing: {video_file}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "\n",
        "    # Initialize time series containers\n",
        "    ts_body = [columns_body]\n",
        "    ts_hands = [columns_hands]\n",
        "    ts_face = [columns_face]\n",
        "    time_ms = 0.0\n",
        "\n",
        "    with mp_holistic.Holistic(\n",
        "        static_image_mode=False,   # enables MediaPipe built-in smoothing\n",
        "        model_complexity=1,\n",
        "        enable_segmentation=False,\n",
        "        refine_face_landmarks=True\n",
        "    ) as holistic:\n",
        "        while True:\n",
        "            ok, frame = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = holistic.process(image_rgb)\n",
        "\n",
        "            # Body\n",
        "            if results.pose_landmarks is not None:\n",
        "                body_vals = []\n",
        "                for lm in results.pose_landmarks.landmark:\n",
        "                    body_vals.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
        "            else:\n",
        "                body_vals = [np.nan] * (len(columns_body) - 1)\n",
        "\n",
        "            # Hands (left + right)\n",
        "            def hand_vals(landmarks):\n",
        "                if landmarks is None:\n",
        "                    return [np.nan] * (21 * 3)\n",
        "                vals = []\n",
        "                for lm in landmarks.landmark:\n",
        "                    vals.extend([lm.x, lm.y, lm.z])\n",
        "                return vals\n",
        "\n",
        "            left_hand = hand_vals(results.left_hand_landmarks)\n",
        "            right_hand = hand_vals(results.right_hand_landmarks)\n",
        "            hands_vals = left_hand + right_hand\n",
        "\n",
        "            # Face\n",
        "            if results.face_landmarks is not None:\n",
        "                face_vals = []\n",
        "                for lm in results.face_landmarks.landmark:\n",
        "                    face_vals.extend([lm.x, lm.y, lm.z])\n",
        "            else:\n",
        "                face_vals = [np.nan] * (len(columns_face) - 1)\n",
        "\n",
        "            # Insert time and append rows\n",
        "            row_body = [time_ms] + body_vals\n",
        "            row_hands = [time_ms] + hands_vals\n",
        "            row_face = [time_ms] + face_vals\n",
        "\n",
        "            ts_body.append(row_body)\n",
        "            ts_hands.append(row_hands)\n",
        "            ts_face.append(row_face)\n",
        "\n",
        "            time_ms += (1000.0 / fps)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Save CSVs\n",
        "    with open(os.path.join(output_folder, f\"{base}_body.csv\"), \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerows(ts_body)\n",
        "    with open(os.path.join(output_folder, f\"{base}_hands.csv\"), \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerows(ts_hands)\n",
        "    with open(os.path.join(output_folder, f\"{base}_face.csv\"), \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerows(ts_face)\n",
        "\n",
        "    print(f\"Saved: {base}_body.csv, {base}_hands.csv, {base}_face.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Video (Optional)\n",
        "\n",
        "Play the input video to visually inspect the content before/after processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Video, display\n",
        "\n",
        "# Preview the first video (if present)\n",
        "if len(video_files) > 0:\n",
        "    preview_path = os.path.join(input_folder, video_files[0])\n",
        "    print(\"Previewing:\", video_files[0])\n",
        "    display(Video(preview_path, embed=True, width=640))\n",
        "else:\n",
        "    print(\"No videos found in:\", input_folder)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Done\n",
        "\n",
        "CSV files have been saved to `../results/Output_TimeSeries/`. Use these files for downstream smoothing of derivatives (speed, acceleration, jerk) or other analyses.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
